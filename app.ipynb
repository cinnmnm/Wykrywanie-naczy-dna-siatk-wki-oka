{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DLUnet v2.0.0] Retinal Vessel Segmentation Package Loaded\n",
      "Available interfaces:\n",
      "  â€¢ VesselSegmentationPipeline - Complete training/inference pipeline\n",
      "  â€¢ VesselSegmentationController - Simple controller interface\n",
      "  â€¢ Core components for custom implementations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4f8868c33a4b0f83f17f842b2c5e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FileUpload(value=(), accept='image/*', description='Choose Image', layout=Layoutâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from App.GUI import GUI\n",
    "from App.DemoController import DemoController\n",
    "import os\n",
    "\n",
    "print(\"ğŸ©¸ğŸ‘ï¸ Retinal Vessel Segmentation Application\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Initialize demo controller (automatically loads demo model)\n",
    "controller = DemoController(auto_load_demo=True)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Available segmentation methods: {controller.get_available_methods()}\")\n",
    "\n",
    "if 'deep_learning' in controller.get_available_methods():\n",
    "    model_info = controller.get_model_info()\n",
    "    print(f\"\\nğŸ¤– Deep Learning Model Info:\")\n",
    "    print(f\"   Model Type: {model_info['model_type']}\")\n",
    "    print(f\"   Parameters: {model_info['parameters']:,}\")\n",
    "    print(f\"   Device: {model_info['device']}\")\n",
    "    print(f\"   Target Size: {model_info['target_size']}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Deep learning model not available, using filter-based segmentation only\")\n",
    "\n",
    "print(\"\\nğŸ–¥ï¸ Initializing GUI...\")\n",
    "\n",
    "# Initialize and launch GUI\n",
    "gui = GUI(controller)\n",
    "gui.init()\n",
    "\n",
    "print(\"âœ… GUI ready! Use the interface above to:\")\n",
    "print(\"   1. Upload retinal images\")\n",
    "print(\"   2. Select segmentation method(s):\")\n",
    "print(\"      â€¢ Prosty Model = Filter-based segmentation\")\n",
    "print(\"      â€¢ DL Model = Deep learning segmentation\") \n",
    "print(\"   3. Click Start to process\")\n",
    "print(\"\\nğŸ¯ Ready for vessel segmentation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd0e88",
   "metadata": {},
   "source": [
    "# Wykrywanie naczyÅ„ dna siatkÃ³wki oka\n",
    "\n",
    "## Opis\n",
    "\n",
    "Przygotowanie aplikacji, ktÃ³ra dla zadanego obrazu wejÅ›ciowego przedstawiajÄ…cego dno siatkÃ³wki oka automatycznie wykrywa naczynia krwionoÅ›ne. Z formalnego punktu widzenia dla kaÅ¼dego piksela wykorzystany algorytm musi stwierdziÄ‡, czy ten piksel stanowi naczynie krwionoÅ›ne, czy nie (klasyfikacja binarna).\n",
    "\n",
    "## Wymagania obowiÄ…zkowe\n",
    "\n",
    "Algorytm w podstawowej wersji powinien wykorzystywaÄ‡ techniki przetwarzania obrazu do detekcji naczyÅ„ krwionoÅ›nych. W ramach takiego procesu przetwarzania moÅ¼na wyrÃ³Å¼niÄ‡ 3 gÅ‚Ã³wne elementy:\n",
    "\n",
    "1. **WstÄ™pne przetworzenie obrazu**  \n",
    "   WejÅ›ciowy obraz moÅ¼e byÄ‡ zaszumiony/zbyt ciemny/jasny. MoÅ¼na tutaj wykorzystaÄ‡ takie techniki jak: rozmycie, wyostrzenie, normalizacja histogramu kolorÃ³w itp.\n",
    "\n",
    "2. **WÅ‚aÅ›ciwe przetworzenie obrazu**  \n",
    "   W celu wyodrÄ™bnienia naczyÅ„ krwionoÅ›nych moÅ¼na zastosowaÄ‡ rÃ³Å¼ne techniki wykrywania krawÄ™dzi (np. filtr Frangiâ€™ego).\n",
    "\n",
    "3. **KoÅ„cowe przetwarzanie obrazu**  \n",
    "   Przetwarzanie uzyskanego obrazu w celu poprawy skutecznoÅ›ci wykrywania naczyÅ„ poprzez â€œnaprawÄ™â€ bÅ‚Ä™dÃ³w z poprzednich krokÃ³w.\n",
    "\n",
    "Wynik naleÅ¼y wizualizowaÄ‡, np. zamalowujÄ…c wyrÃ³Å¼niajÄ…cym siÄ™ kolorem piksele zaklasyfikowane jako naczynie krwionoÅ›ne. Najlepiej wygenerowaÄ‡ binarnÄ… maskÄ™ odpowiedzi algorytmu, ktÃ³ra zostanie potem wykorzystana do analizy statystycznej (porÃ³wnanie z maskÄ… eksperckÄ… z rÄ™cznie zaznaczonymi naczyniami).\n",
    "\n",
    "WaÅ¼nym elementem oceny jest skutecznoÅ›Ä‡ algorytmu. W tym celu naleÅ¼y dokonaÄ‡ podstawowej analizy statystycznej jakoÅ›ci dziaÅ‚ania algorytmu. DziaÅ‚anie programu naleÅ¼y przetestowaÄ‡ na minimum 5 obrazach. Podczas testÃ³w naleÅ¼y wyznaczyÄ‡:\n",
    "\n",
    "- macierze pomyÅ‚ek,\n",
    "- trafnoÅ›Ä‡ (accuracy),\n",
    "- czuÅ‚oÅ›Ä‡ (sensitivity),\n",
    "- swoistoÅ›Ä‡ (specificity).\n",
    "\n",
    "Przy wyznaczaniu czuÅ‚oÅ›ci i swoistoÅ›ci naleÅ¼y zaÅ‚oÅ¼yÄ‡, Å¼e naczynie to klasa pozytywna, a tÅ‚o â€” negatywna. PoniewaÅ¼ mamy do czynienia z niezrÃ³wnowaÅ¼onym rozkÅ‚adem klas, naleÅ¼y dodatkowo wykorzystaÄ‡ miary dla danych niezrÃ³wnowaÅ¼onych (np. Å›redniÄ… arytmetycznÄ… lub geometrycznÄ… czuÅ‚oÅ›ci i swoistoÅ›ci).\n",
    "\n",
    "## Wymagania na 4.0\n",
    "\n",
    "Po wstÄ™pnym przetworzeniu obrazu naleÅ¼y podzieliÄ‡ go na wycinki (np. 5x5 px) i dla kaÅ¼dej z nich dokonaÄ‡ ekstrakcji cech z obrazu: np. wariancja kolorÃ³w, momenty centralne, momenty Hu itp. WartoÅ›ci te wraz z informacjÄ… pochodzÄ…cÄ… z maski eksperckiej (decyzja dla Å›rodkowego piksela wycinka) stanowiÄ‡ bÄ™dÄ… zbiÃ³r danych wykorzystany do budowy wybranego klasyfikatora, prostszego niÅ¼ gÅ‚Ä™boka sieÄ‡ neuronowa (np. kNN, drzewo lub las decyzyjny, SVM). NaleÅ¼y skorzystaÄ‡ z gotowej implementacji klasyfikatora (np. w bibliotece scikit-learn).\n",
    "\n",
    "Z uwagi na ograniczenia pamiÄ™ciowe konieczne moÅ¼e byÄ‡ ograniczenie rozmiaru zbioru uczÄ…cego poprzez losowy wybÃ³r punktÃ³w (moÅ¼liwoÅ›Ä‡ zastosowania undersamplingu do zrÃ³wnowaÅ¼enia rozkÅ‚adu klas w zbiorze uczÄ…cym).\n",
    "\n",
    "ZdolnoÅ›ci predykcyjne tak opracowanego klasyfikatora naleÅ¼y wstÄ™pnie zweryfikowaÄ‡ na niezaleÅ¼nym zbiorze testowym hold-out (np. pochodzÄ…cym z innej czÄ™Å›ci obrazu lub z innego obrazu).\n",
    "\n",
    "Gotowy klasyfikator powinien zostaÄ‡ osadzony w aplikacji, a jego dziaÅ‚anie powinno zostaÄ‡ zwizualizowane i przetestowane w taki sam sposÃ³b, jak dziaÅ‚anie technik przetwarzania obrazu z wymagaÅ„ podstawowych.\n",
    "\n",
    "## Wymagania na 5.0\n",
    "\n",
    "Jako model decyzyjny naleÅ¼y wykorzystaÄ‡ gÅ‚Ä™bokÄ… sieÄ‡ neuronowÄ…. W zaleÅ¼noÅ›ci od wybranego rodzaju sieci, moÅ¼e zostaÄ‡ ona nauczona na wycinkach obrazu (podobnie jak w przypadku wymagaÅ„ na 4.0), jak i na caÅ‚ych obrazach (np. w przypadku sieci UNet). NaleÅ¼y skorzystaÄ‡ z gotowej implementacji sieci (np. w bibliotece Keras, PyTorch lub TensorFlow).\n",
    "\n",
    "ZdolnoÅ›ci predykcyjne nauczonej sieci neuronowej powinny byÄ‡ wstÄ™pnie zweryfikowane na zbiorze testowym hold-out.\n",
    "\n",
    "Nauczona sieÄ‡ powinna zostaÄ‡ osadzona w aplikacji i tam dodatkowo przetestowana zgodnie z wymaganiami obowiÄ…zkowymi.\n",
    "\n",
    "## Uwaga\n",
    "\n",
    "W projekcie naleÅ¼y skorzystaÄ‡ z jednej z dostÄ™pnych baz danych z obrazami (patrz linki poniÅ¼ej) â€” ta sama baza powinna byÄ‡ stosowana we wszystkich krokach projektu.\n",
    "\n",
    "## Linki\n",
    "\n",
    "- Baza obrazÃ³w HRF: https://www5.cs.fau.de/research/data/fundus-images/  \n",
    "  (proszÄ™ siÄ™ nie przejmowaÄ‡ komunikatem â€œwebsite deprecated and outdatedâ€).\n",
    "\n",
    "- Baza obrazÃ³w STARE: http://cecas.clemson.edu/~ahoover/stare/probing/  \n",
    "- Baza obrazÃ³w CHASE: https://blogs.kingston.ac.uk/retinal/chasedb1/  \n",
    "  (przeglÄ…danie zdjÄ™Ä‡ nie dziaÅ‚a, moÅ¼na jednak pobraÄ‡ caÅ‚e archiwum)\n",
    "\n",
    "- Biblioteka scikit-learn: https://scikit-learn.org/stable/  \n",
    "- Biblioteka imbalanced-learn: https://imbalanced-learn.org/stable/  \n",
    "\n",
    "- P. Liskowski, K. Krawiec: *Segmenting Retinal Blood Vessels With Deep Neural Networks*: https://ieeexplore.ieee.org/document/7440871  \n",
    "\n",
    "- Implementacja sieci UNet z wykorzystaniem biblioteki PyTorch:  \n",
    "  - https://pyimagesearch.com/2023/11/06/image-segmentation-with-u-net-in-pytorch-the-grand-finale-of-the-autoencoder-series/  \n",
    "  - https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/  \n",
    "\n",
    "- MONAI: Medical Open Network for AI: https://monai.io/  \n",
    "\n",
    "- PrzykÅ‚adowa implementacja sieci UNet z wykorzystaniem biblioteki Keras:  \n",
    "  - https://github.com/zhixuhao/unet  \n",
    "  - https://github.com/karolzak/keras-unet  \n",
    "  - https://github.com/qubvel/segmentation_models  \n",
    "\n",
    "- Segmentacja obrazu z wykorzystaniem TensorFlow: https://www.tensorflow.org/tutorials/images/segmentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
